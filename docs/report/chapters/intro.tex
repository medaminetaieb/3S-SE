\chapter{Introduction}
This chapter is a prolusion to the conceptualization of this end-of-studies project. It lays out the context and influences which made it relevant in current settings.\newline
First, it describes the background and sequence of developments that brought much of the employed technologies into existence. Next, it introduces the hosting company and discusses its necessity for a such solution. And finally, it walks through the pursued objectives and innovations which address the insufficiencies of existing solutions.
\newpage

\section{Background}
Business Knowledge is both integral and proprietary for any enterprise. The contents of private documents are useful for internal employees who are constantly consuming it to accomplish their workstreams. It becomes evident when considering that modern software development and network infrastructure deployment (among many other fields) are often based on exhaustive documentation and lengthy research papers. Paradoxically, this upfront research and learning introduce a sort of bottleneck requiring much time before a new project is initiated. In most cases, a further looking up for previously reviewed information is often required. Accelerating delivery, however, remains a key objective for organizations seeking a competitive edge. This together emphasizes the need to consider and propose innovative solutions which would help reduce the preliminary requirements and achieve a faster time-to-market (TTM).\medskip\newline
In line with this discussion, it is worth highlighting the evolving landscape of web search in the contemporary era. We used to input a query into a search engine (e.g. Google) and it would look through its indexed webpages and then return a list of the most relevant pages which we would read until we have a satisfying answer. This paradigm has veered towards generative AI chatbot solutions, like ChatGPT, Copilot and Gemini, which leverage Machine Learning algorithms to mimic the natural language understanding capability of humans to generate short and accurate answers.\smallskip\newline
Auspiciously, the underlying technology which empower this kind of chatbots is discrete from their corresponding platforms, i.e., it can be integrated in other projects as a library or software component rather than being exclusive to their native applications. This presents an interesting topic for an internship project which will both provide a much needed solution for an entreprise with many activities and projects to accomplish and for a data science student aspiring to continuously learn the newest trends in AI and Machine Learning.
\newpage

\section{Hosting Company}
The hosting of this project was managed by Standard Sharing Software (3S).
\smallskip\newline
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figures/logo_3S.png}
    \caption{Standard Sharing Software logo}
\end{figure}\newline
3S is a Tunisian IT services company specializing in the integration of IT infrastructures. Since its foundation in 1988, it has supported its clients in their digital transformation, management and improvement of their IT infrastructure, from the study to the deployment of the most innovative and high value-added technological solutions.
It is based (headquarters) in Montplaisir, Tunis, Tunisia, and in Charguia 1, Tunis (the office where this internship was conducted), with different teams specializing in Network and Telecommunication infrastructures, Cyber security, and Cloud Computing. This project was organized in AI and development department, but close collaboration with these different units was required since they constitute the target users of this project.
\newpage

\section{Problem Statement}
Traditional enterprise search engines often have many limitations due to the complexity of user query context comprehension and human language understanding. This is true because traditional methods of content searching is based on exact text matching without semantic-based retrieval. Even with the emergence of AI tools like ChatGPT, which address Natural Language Processing/Analysis, access to large enterprise data is still a major hurdle for such systems. We have witnessed in recent years the amount of pressure governments have put on AI products in order to evade potential privacy and copyright infringements. This is good overall as such regulations ensure fair competition and publishers' rights. However, this also means that companies need to develop their own solutions to effectively leverage the recent breakthroughs of this field.\medskip\newline
In the table below, an identification and comparison between a few existing solutions has been undertaken to understand their limitations and how to improve on them.
\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \toprule
        \textcolor{darkgray}{\textbf{\makecell{Solution}}}  & \textbf{\makecell{LLM                                                                                                                              \\Chatbots}}                                     & \textbf{\makecell{NotebookLM}}                                       & \textbf{\makecell{Verba}}                                             \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{Developer}}} & \makecell{Google, OpenAI                                                                                                                           \\and Microsoft}                                 & Google                                                    & Weaviate                                                   \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{RAG-based                                                                                                                                                         \\ (persistent storage)}}} & \textcolor{red}{\ding{56}}        & \textcolor{green}{\ding{52}}                                & \textcolor{green}{\ding{52}}  / \textcolor{red}{\ding{56}} \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{Enterprise                                                                                                                                                        \\focused}}} & \textcolor{red}{\ding{56}}                                & \textcolor{red}{\ding{56}}                                & \textcolor{green}{\ding{52}}  / \textcolor{red}{\ding{56}} \\
        \midrule
        \textcolor{darkgray}{\textbf{Extensible}}           & \textcolor{green}{\ding{52}} / \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{green}{\ding{52}} / \textcolor{red}{\ding{56}} \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{Multiple                                                                                                                                                          \\LLMs}}}      & \textcolor{red}{\ding{56}}                                & \textcolor{red}{\ding{56}}                                & \textcolor{green}{\ding{52}}                               \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{User-LLM                                                                                                                                                          \\feedback}}}  & \textcolor{green}{\ding{52}} & \textcolor{red}{\ding{56}} / \textcolor{green}{\ding{52}} & \textcolor{red}{\ding{56}}                                 \\
        \midrule
        \textcolor{darkgray}{\textbf{\makecell{Stable                                                                                                                                                            \\ (Not experimental)}}} & \textcolor{green}{\ding{52}} & \textcolor{red}{\ding{56}}                                & \textcolor{red}{\ding{56}}                                 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of existing solutions}
\end{table}\newline
In general, one can use any ready-to-use LLM-powered chatbot (e.g. ChatGPT, Microsoft Copilot, Google Gemini, and many others), but these solutions, even though allowing document-answering, don't come with document persistence, which means by leaving the chat, the documents are gone unless re-uploaded.\newline
Google is experimenting with a new solution (NotebookLM) that allows that by connecting to cloud-hosted documents, in addition to methods allowing to upload local files and webpage content from URLs, but this comes short for enterprise use as it is intended for casual use cases like note taking, document editing suggestions and personal project research. On the other hand, Weaviate, a company behind a vector store development, maintains \href{https://github.com/weaviate/Verba}{a repository on GitHub} which addresses the same objectives as this project. Their solution, called Verba, is a well-organized open-source project that can be easily deployed on-premises or in a cloud environment. However, several challenges have to be faced before a company can adapt it to their specific needs: customization is difficult given that the project uses many dependencies from packages they developed (goldenverba, weaviate), requiring many API keys from various providers (vector database, LLMs, cloud providers, etc...), in addition to the inability to create and manage different databases for different teams.\smallskip\newline
This scarcity and inadequacy of available projects raises the need to design and develop a custom solution suitable for the needs and requirements set up by individual enterprises (which is articulated in the next section).
\newpage
\section{Objectives}
This project aims to address general-purpose large language models' limitations (data confinement to training phase and private data access) by developing a novel search functionality that leverages retrieval-augmented generation to deliver insightful results for enterprise data. The system will address the following objectives:
\begin{itemize}
    \item Enhance AI-generated responses with External Knowledge: Retrieve relevant passages from a curated enterprise knowledge base each time an LLM is prompted to improve its factual grounding and reduce hallucination.
    \item Flexible Data Ingestion and Organization: Implement diverse methods for multi-source, offline and online, format-agnostic file content and document indexing into manageable, domain-specific vector databases to tailor to enterprise needs and potential evolution.
    \item Diverse Answering Options: Allow for the selection of Large Language Models for answering and just-in-time data scraping and fetching to diversify and improve results each time.
    \item User-Driven Feedback: Integrate a mechanism for providing feedback by users for LLM-generated responses which can be used to rank future results and further train and improve LLMs (when supported).
    \item Leverage RAG-based metrics for evaluation: Employ retrieval-augmented generation evaluation metrics to assess the quality of pipeline stages (retrieval quality/accuracy, context-generation consistency, answer relevancy)
\end{itemize}
\newpage
\section{Significance of the study}
The proposed Generative AI solution would help employees to find answers based on enterprise knowledge without having to browse vast amount of documents. This is enabled by LLM knowledge augmentation using techniques of retrieval-augmented generation and prompt engineering for context precision which would also reduce LLM hallucination. It would also allow them to interfere in the steps of answer-generation by providing ways to customize the external knowledge base and conduct online researching, powered by traditional search engines and generative AI researching tools, through a unified interface.