\begin{abstract}
    This report presents the development of a retrieval-augmented generation system using LangChain, Large Language Models and a vector store. The goal is to enhance enterprise information retrieval by generating more accurate and relevant responses to user questions in an enterprise environment.\medskip\newline
    With the recent advancements in Generative Artificial Intelligence and the emergence of open-source Large Language Models, a Generative AI-powered chatbot became an interesting approach for question-answering tasks and faster access to relevant information. Because Large Language Models would require intensive computing power and time to train (in addition to a highly-competitive, multi-disciplinary large teams), using already pre-trained models is the go-to solution for most enterprises. This comes with the drawback of LLMs being confined to the data they were trained on and the general-purpose aspect of their nature. Thus, the need to further develop and improve their functionality with retrieval-augmented generation and other techniques. These would allow to augment the data accessible by large language models and customize how to retrieve it from specific databases (vector stores).\bigskip\newline
    \textit{\textbf{Keywords:} Generative AI, Large Language Models (LLMs), Retrieval-augmented Generation (RAG), LangChain, Prompt Engineering, Embeddings, Vector Store}
\end{abstract}