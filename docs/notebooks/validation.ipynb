{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "db = FAISS.from_documents(\n",
    "    PyMuPDFLoader(\"./2312.10997v5.pdf\").load_and_split(),\n",
    "    HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': './2312.10997v5.pdf', 'file_path': './2312.10997v5.pdf', 'page': 0, 'total_pages': 21, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240328005445Z', 'modDate': 'D:20240328005445Z', 'trapped': ''}, page_content='fine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. This survey endeavors to\\nfill this gap by mapping out the RAG process and charting\\nits evolution and anticipated future paths, with a focus on the\\nintegration of RAG within LLMs. This paper considers both\\ntechnical paradigms and research methods, summarizing three\\nmain research paradigms from over 100 RAG studies, and\\nanalyzing key technologies in the core stages of “Retrieval,”\\n“Generation,” and “Augmentation.” On the other hand, current\\nresearch tends to focus more on methods, lacking analysis and\\nsummarization of how to evaluate RAG. This paper compre-\\nhensively reviews the downstream tasks, datasets, benchmarks,\\nand evaluation methods applicable to RAG. Overall, this\\npaper sets out to meticulously compile and categorize the\\nfoundational technical concepts, historical progression, and\\nthe spectrum of RAG methodologies and applications that\\nhave emerged post-LLMs. It is designed to equip readers and\\nprofessionals with a detailed and structured understanding of\\nboth large models and RAG. It aims to illuminate the evolution\\nof retrieval augmentation techniques, assess the strengths and\\nweaknesses of various approaches in their respective contexts,\\nand speculate on upcoming trends and innovations.\\nOur contributions are as follows:\\n• In this survey, we present a thorough and systematic\\nreview of the state-of-the-art RAG methods, delineating\\nits evolution through paradigms including naive RAG,\\narXiv:2312.10997v5  [cs.CL]  27 Mar 2024'),\n",
       "  0.37452614314189936),\n",
       " (Document(metadata={'source': './2312.10997v5.pdf', 'file_path': './2312.10997v5.pdf', 'page': 6, 'total_pages': 21, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240328005445Z', 'modDate': 'D:20240328005445Z', 'trapped': ''}, page_content='the retrieved data. Coarse-grained retrieval units theoretically\\ncan provide more relevant information for the problem, but\\nthey may also contain redundant content, which could distract\\nthe retriever and language models in downstream tasks [50],\\n[87]. On the other hand, fine-grained retrieval unit granularity\\nincreases the burden of retrieval and does not guarantee seman-\\ntic integrity and meeting the required knowledge. Choosing'),\n",
       "  0.2994688858244252),\n",
       " (Document(metadata={'source': './2312.10997v5.pdf', 'file_path': './2312.10997v5.pdf', 'page': 10, 'total_pages': 21, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240328005445Z', 'modDate': 'D:20240328005445Z', 'trapped': ''}, page_content='11\\nFig. 5. In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes. (left) Iterative retrieval involves\\nalternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step. (Middle) Recursive retrieval\\ninvolves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval\\nand generation. (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary\\nand when to stop retrieval and generation, often utilizing LLM-generated special tokens for control.\\nbase for LLMs. This approach has been shown to enhance\\nthe robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-\\ntinuity and the accumulation of irrelevant information. ITER-\\nRETGEN [14] employs a synergistic approach that lever-\\nages “retrieval-enhanced generation” alongside “generation-\\nenhanced retrieval” for tasks that necessitate the reproduction\\nof specific information. The model harnesses the content\\nrequired to address the input task as a contextual basis for\\nretrieving pertinent knowledge, which in turn facilitates the\\ngeneration of improved responses in subsequent iterations.\\nB. Recursive Retrieval\\nRecursive retrieval is often used in information retrieval and\\nNLP to improve the depth and relevance of search results.\\nThe process involves iteratively refining search queries based\\non the results obtained from previous searches. Recursive\\nRetrieval aims to enhance the search experience by gradu-\\nally converging on the most pertinent information through a\\nfeedback loop. IRCoT [61] uses chain-of-thought to guide\\nthe retrieval process and refines the CoT with the obtained\\nretrieval results. ToC [57] creates a clarification tree that\\nsystematically optimizes the ambiguous parts in the Query. It\\ncan be particularly useful in complex search scenarios where\\nthe user’s needs are not entirely clear from the outset or where\\nthe information sought is highly specialized or nuanced. The\\nrecursive nature of the process allows for continuous learning\\nand adaptation to the user’s requirements, often resulting in\\nimproved satisfaction with the search outcomes.\\nTo address specific data scenarios, recursive retrieval and\\nmulti-hop retrieval techniques are utilized together. Recursive\\nretrieval involves a structured index to process and retrieve\\ndata in a hierarchical manner, which may include summarizing\\nsections of a document or lengthy PDF before performing a\\nretrieval based on this summary. Subsequently, a secondary\\nretrieval within the document refines the search, embodying\\nthe recursive nature of the process. In contrast, multi-hop\\nretrieval is designed to delve deeper into graph-structured data\\nsources, extracting interconnected information [106].\\nC. Adaptive Retrieval\\nAdaptive retrieval methods, exemplified by Flare [24] and\\nSelf-RAG [25], refine the RAG framework by enabling LLMs\\nto actively determine the optimal moments and content for\\nretrieval, thus enhancing the efficiency and relevance of the\\ninformation sourced.\\nThese methods are part of a broader trend wherein\\nLLMs employ active judgment in their operations, as seen\\nin model agents like AutoGPT, Toolformer, and Graph-\\nToolformer [107]–[109]. Graph-Toolformer, for instance, di-\\nvides its retrieval process into distinct steps where LLMs\\nproactively use retrievers, apply Self-Ask techniques, and em-\\nploy few-shot prompts to initiate search queries. This proactive\\nstance allows LLMs to decide when to search for necessary\\ninformation, akin to how an agent utilizes tools.\\nWebGPT [110] integrates a reinforcement learning frame-\\nwork to train the GPT-3 model in autonomously using a\\nsearch engine during text generation. It navigates this process'),\n",
       "  0.28909966527268394),\n",
       " (Document(metadata={'source': './2312.10997v5.pdf', 'file_path': './2312.10997v5.pdf', 'page': 17, 'total_pages': 21, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240328005445Z', 'modDate': 'D:20240328005445Z', 'trapped': ''}, page_content='18\\n[44] B. Wang, W. Ping, P. Xu, L. McAfee, Z. Liu, M. Shoeybi, Y. Dong,\\nO. Kuchaiev, B. Li, C. Xiao et al., “Shall we pretrain autoregressive\\nlanguage models with retrieval? a comprehensive study,” arXiv preprint\\narXiv:2304.06762, 2023.\\n[45] B. Wang, W. Ping, L. McAfee, P. Xu, B. Li, M. Shoeybi, and B. Catan-\\nzaro, “Instructretro: Instruction tuning post retrieval-augmented pre-\\ntraining,” arXiv preprint arXiv:2310.07713, 2023.\\n[46] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana,\\nand S. Nanayakkara, “Improving the domain adaptation of retrieval\\naugmented generation (rag) models for open domain question answer-\\ning,” Transactions of the Association for Computational Linguistics,\\nvol. 11, pp. 1–17, 2023.\\n[47] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\\nimproves generalization of language models as generic plug-in,” arXiv\\npreprint arXiv:2305.17331, 2023.\\n[48] O. Yoran, T. Wolfson, O. Ram, and J. Berant, “Making retrieval-\\naugmented language models robust to irrelevant context,” arXiv\\npreprint arXiv:2310.01558, 2023.\\n[49] H.-T. Chen, F. Xu, S. A. Arora, and E. Choi, “Understanding re-\\ntrieval augmentation for long-form question answering,” arXiv preprint\\narXiv:2310.12150, 2023.\\n[50] W. Yu, H. Zhang, X. Pan, K. Ma, H. Wang, and D. Yu, “Chain-of-note:\\nEnhancing robustness in retrieval-augmented language models,” arXiv\\npreprint arXiv:2311.09210, 2023.\\n[51] S. Xu, L. Pang, H. Shen, X. Cheng, and T.-S. Chua, “Search-in-the-\\nchain: Towards accurate, credible and traceable large language models\\nfor knowledgeintensive tasks,” CoRR, vol. abs/2304.14732, 2023.\\n[52] M. Berchansky, P. Izsak, A. Caciularu, I. Dagan, and M. Wasserblat,\\n“Optimizing retrieval-augmented reader models via token elimination,”\\narXiv preprint arXiv:2310.13682, 2023.\\n[53] J. L´\\nala, O. O’Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques,\\nand A. D. White, “Paperqa: Retrieval-augmented generative agent for\\nscientific research,” arXiv preprint arXiv:2312.07559, 2023.\\n[54] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\\nY. Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\\nRedefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\\n2024.\\n[55] Z. Zhang, X. Zhang, Y. Ren, S. Shi, M. Han, Y. Wu, R. Lai, and\\nZ. Cao, “Iag: Induction-augmented generation framework for answer-\\ning reasoning questions,” in Proceedings of the 2023 Conference on\\nEmpirical Methods in Natural Language Processing, 2023, pp. 1–14.\\n[56] N. Thakur, L. Bonifacio, X. Zhang, O. Ogundepo, E. Kamalloo,\\nD. Alfonso-Hermelo, X. Li, Q. Liu, B. Chen, M. Rezagholizadeh et al.,\\n“Nomiracl: Knowing when you don’t know for robust multilingual\\nretrieval-augmented generation,” arXiv preprint arXiv:2312.11361,\\n2023.\\n[57] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\\ntions: Answering ambiguous questions with retrieval-augmented large\\nlanguage models,” arXiv preprint arXiv:2310.14696, 2023.\\n[58] Y. Wang, P. Li, M. Sun, and Y. Liu, “Self-knowledge guided\\nretrieval augmentation for large language models,” arXiv preprint\\narXiv:2310.05002, 2023.\\n[59] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\\ngeneration synergy augmented large language models,” arXiv preprint\\narXiv:2310.05149, 2023.\\n[60] P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,\\nE. Bakhturina, M. Shoeybi, and B. Catanzaro, “Retrieval meets long\\ncontext large language models,” arXiv preprint arXiv:2310.03025,\\n2023.\\n[61] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\\ning retrieval with chain-of-thought reasoning for knowledge-intensive\\nmulti-step questions,” arXiv preprint arXiv:2212.10509, 2022.\\n[62] R. Ren, Y. Wang, Y. Qu, W. X. Zhao, J. Liu, H. Tian, H. Wu, J.-\\nR. Wen, and H. Wang, “Investigating the factual knowledge boundary\\nof large language models with retrieval augmentation,” arXiv preprint\\narXiv:2307.11019, 2023.\\n[63] P. Sarthi, S. Abdullah, A. Tuli, S. Khanna, A. Goldie, and C. D.'),\n",
       "  0.2674217709158937)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search_with_relevance_scores(\n",
    "    \"what are the different types of retrieval augmentation processes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(temperature=0, model_name=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval augmentation is a powerful technique used in information retrieval to improve the accuracy and relevance of search results. It involves enriching the original query with additional information to guide the retrieval process more effectively. \n",
      "\n",
      "Here are some common types of retrieval augmentation processes:\n",
      "\n",
      "**1. Query Expansion:**\n",
      "\n",
      "* **Synonym Replacement:** Replacing words in the query with their synonyms to capture different meanings and related concepts.\n",
      "* **Word Sense Disambiguation:** Identifying the intended meaning of ambiguous words in the query and using the appropriate sense for retrieval.\n",
      "* **Concept Expansion:** Adding related concepts or terms to the query based on semantic relationships, ontologies, or knowledge graphs.\n",
      "* **Negation Handling:** Identifying and incorporating negation terms (e.g., \"not,\" \"without\") to refine the search scope.\n",
      "\n",
      "**2. Document Augmentation:**\n",
      "\n",
      "* **Passage Retrieval:** Instead of retrieving entire documents, focus on finding relevant passages within documents that directly address the query.\n",
      "* **Document Summarization:** Generating concise summaries of documents to provide a quick overview and highlight key information.\n",
      "* **Document Clustering:** Grouping similar documents together to identify topical clusters and retrieve more focused results.\n",
      "\n",
      "**3. Contextual Augmentation:**\n",
      "\n",
      "* **User History:** Incorporating the user's past search queries and interactions to personalize results and understand their interests.\n",
      "* **Session Context:** Utilizing information from the current browsing session, such as clicked links or visited pages, to refine the search.\n",
      "* **External Knowledge:** Integrating knowledge from external sources, such as Wikipedia or specialized databases, to provide richer context.\n",
      "\n",
      "**4. Hybrid Augmentation:**\n",
      "\n",
      "* **Combining multiple techniques:** Using a combination of query expansion, document augmentation, and contextual augmentation to achieve more comprehensive and accurate retrieval.\n",
      "\n",
      "**5. Learning-Based Augmentation:**\n",
      "\n",
      "* **Neural Networks:** Training deep learning models to automatically generate augmented queries or documents based on patterns and relationships in the data.\n",
      "\n",
      "**Choosing the right retrieval augmentation process depends on factors such as:**\n",
      "\n",
      "* **The type of information being searched:** Different domains and tasks may benefit from specific augmentation techniques.\n",
      "* **The size and structure of the dataset:** Some techniques may be more suitable for large-scale datasets, while others may be more effective for smaller, specialized collections.\n",
      "* **The computational resources available:** Some augmentation methods can be computationally expensive, while others are more lightweight.\n",
      "\n",
      "By carefully selecting and implementing retrieval augmentation processes, search engines and information retrieval systems can significantly improve the quality and relevance of search results, providing users with a more valuable and satisfying search experience.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "for chunk in chain.stream({\"text\": \"what are the different types of retrieval augmentation processes\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are three main types of retrieval augmentation processes: iterative retrieval, recursive retrieval, and adaptive retrieval.  Thanks for asking! \\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": db.as_retriever() | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"what are the different types of retrieval augmentation processes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
